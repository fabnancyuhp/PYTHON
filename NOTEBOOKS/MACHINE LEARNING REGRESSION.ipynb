{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation d'algorithme de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataframe boston_house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target_price  \n",
       "0     15.3  396.90   4.98          24.0  \n",
       "1     17.8  396.90   9.14          21.6  \n",
       "2     17.8  392.83   4.03          34.7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "dir(boston)\n",
    "\n",
    "YV = boston.target.reshape(len(boston.target),1)\n",
    "datav = np.concatenate((boston.data,YV),axis=1)\n",
    "feature_name = list(boston.feature_names)+['target_price']\n",
    "\n",
    "boston_house = pd.DataFrame(datav,columns=feature_name)\n",
    "boston_house .head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but des exemples suivant est de prédire la variable target_price en fonction des features CRIM, ZN ,INDUS ,CHAS ,NOX,RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT. On décrit les features:<br>\n",
    "\n",
    "   * CRIM     per capita crime rate by town\n",
    "   * ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "   * INDUS    proportion of non-retail business acres per town\n",
    "   * CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "   * NOX      nitric oxides concentration (parts per 10 million)\n",
    "   * RM       average number of rooms per dwelling\n",
    "   * AGE      proportion of owner-occupied units built prior to 1940\n",
    "   * DIS      weighted distances to five Boston employment centres\n",
    "   * RAD      index of accessibility to radial highways\n",
    "   * TAX      full-value property-tax rate per \\$10,000\n",
    "   * PTRATIO  pupil-teacher ratio by town\n",
    "   * B        $1000(Bk - 0.63)^2$ where Bk is the proportion of blacks by town\n",
    "   * LSTAT     lower status of the population\n",
    "   * MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple : RandomForestRegressor sur le dataframe boston_house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On divise en échantillon d'apprentissage et de test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "var_expl = [o for o in boston_house.columns if o!='target_price']\n",
    "X = boston_house[var_expl]\n",
    "Y = boston_house['target_price']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,\\\n",
    "                                                    random_state=1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On appelle un model de random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=13,\n",
       "           max_features=10, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "           oob_score=False, random_state=2018, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#mae\n",
    "rfr = RandomForestRegressor(n_estimators=15,max_features=10,max_depth=13,\\\n",
    "                            random_state=2018,criterion='mse')\n",
    "rfr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) On calcule le mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.2182917856857305"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(Y_test,rfr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) On calcule le mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1095275590551181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(Y_test,rfr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) On calcule median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7700000000000031"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "median_absolute_error(Y_test,rfr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) On appelle GridSearchCV avec le model RandomForestRegressor. Le nombre d'arbre varie de 10 à 20, le nombre maximum de features varie de 8 à 13, la profondeur maximum va de 9 à 16. On fera une validation croisé à 4 parties (4-fold cross validation). Random_state sera egale à 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=2018,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'max_features': [8, 9, 10, 11, 12, 13], 'max_depth': [9, 10, 11, 12, 13, 14, 15, 16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rdfr = RandomForestRegressor(random_state=2018)\n",
    "\n",
    "parameters = {'n_estimators':list(range(10,21)),'max_features':list(range(8,14)),\\\n",
    "              'max_depth':list(range(9,17))}\n",
    "\n",
    "clf = GridSearchCV(estimator=rdfr,param_grid=parameters,\\\n",
    "                   scoring='neg_mean_squared_error')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13, 'max_features': 8, 'n_estimators': 19}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) On fait un modele RandomForestRegressor avec les clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=13,\n",
       "           max_features=8, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=1,\n",
       "           oob_score=False, random_state=2018, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rdfbest = RandomForestRegressor(n_estimators=19,max_features=8,max_depth= 13,\\\n",
    "                                random_state=2018,criterion='mse')\n",
    "rdfbest.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.1140756016540063"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(Y_test,rdfbest.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats de GridSearchCV sont décevants. On va donc faire une boucle pour trouver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTA = []\n",
    "for nes in range(10,21):\n",
    "    for feat in range(8,14):\n",
    "        for depth in range(9,17):\n",
    "            rdf= RandomForestRegressor(n_estimators=nes,max_features=feat,\\\n",
    "                                       max_depth= depth,random_state=2018,criterion='mse')\n",
    "            rdf.fit(X_train,Y_train)\n",
    "            msetest = mean_squared_error(Y_test,rdf.predict(X_test))\n",
    "            msetrain= mean_squared_error(Y_train,rdf.predict(X_train))\n",
    "            RESULTA.append([nes,feat,depth,msetrain,msetest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple :  réseau de neurone de régression sur le dataframe boston_house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On divise en échantillon d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "var_expl = [o for o in boston_house.columns if o!='target_price']\n",
    "X = boston_house[var_expl]\n",
    "Y = boston_house['target_price']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On appelle un model de réseaux de neurone avec 2 couches cachées de respectivement de 8 perceptrons et 7 perceptrons, avec la fonction d'activation relu et méthode de descente de type newtown avec random_state=2018, une contrainte de pénalisation L2 de 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(8, 7), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=2018,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(hidden_layer_sizes=(8,7), activation='relu',\\\n",
    "                   solver='lbfgs',alpha=0.01,max_iter=500,random_state=2018)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calculer l'erreur quadratique moyenne et l'erreur absolue moyenne du modele l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.749443206205569"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(Y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6050417592175847"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Les scores ne sont pas bon, on va faire un réseau de neurone à une seule couche caché de 5 perceptrons une fonction d'activation relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(14,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=800, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=2018,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg2 = MLPRegressor(hidden_layer_sizes=(14,),activation='relu',\\\n",
    "                    solver='lbfgs',max_iter=800,random_state=2018)\n",
    "\n",
    "reg2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.106325567289062"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(Y_test,reg2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2164597820191552"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test,reg2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple : Epsilon-Support Vector Regression sur le dataframe boston_house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On divise en échantillon d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "var_expl = [o for o in boston_house.columns if o!='target_price']\n",
    "X = boston_house[var_expl]\n",
    "Y = boston_house['target_price']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On scale X_train et X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train_scal = scale.transform(X_train)\n",
    "X_test_scal = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On va utiliser un modele Epsilon-Support Vector Regression avec le kernel rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=40, cache_size=200, coef0=0.0, degree=3, epsilon=4, gamma=0.04,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "SVMR = SVR(kernel='rbf', degree=3, tol=0.001, C=40,gamma=0.04, epsilon=4)\n",
    "SVMR.fit(X_train_scal,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On calcule l'erreur quadratique moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.8437804645633307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(Y_test,SVMR.predict(X_test_scal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) On appelle la fonctionnalité gridsearchcv sur des Epsilon-Support Vector Regression avec le kernel rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['rbf'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'gamma': array([ 0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0....62,  15.41379,  16.06897,\n",
       "        16.72414,  17.37931,  18.03448,  18.68966,  19.34483,  20.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':['rbf'],'C':list(range(1,50)),\\\n",
    "              'gamma':np.arange(0.01,0.2,0.01),'epsilon':np.linspace(1,20,30)}\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "SVRG =  SVR(kernel='rbf')\n",
    "\n",
    "clf = GridSearchCV(estimator=SVRG,param_grid=parameters,scoring='r2')\n",
    "clf.fit(X_train_scal,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) On regarde quels sont les meilleurs parametres et le meilleur score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 49, 'epsilon': 1.0, 'gamma': 0.050000000000000003, 'kernel': 'rbf'}\n",
      "0.818351707863\n"
     ]
    }
   ],
   "source": [
    "print(str(clf.best_params_))\n",
    "print(str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) On appelle le modele avec clf.best_params et on regarde les scores sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=49, cache_size=200, coef0=0.0, degree=3, epsilon=1.0,\n",
       "  gamma=0.050000000000000003, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "best_para = clf.best_params_\n",
    "SVRNEW = SVR(**clf.best_params_)\n",
    "SVRNEW.fit(X_train_scal,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :7.95405664538\n",
      "R2 score :0.921480058423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"MSE :\"+str(mean_squared_error(Y_test,SVRNEW.predict(X_test_scal))))\n",
    "print(\"R2 score :\"+str(r2_score(Y_test,SVRNEW.predict(X_test_scal))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple : GradientBoostingRegressor sur le dataframe boston_house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On divise en échantillon d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "var_expl = [o for o in boston_house.columns if o!='target_price']\n",
    "X = boston_house[var_expl]\n",
    "Y = boston_house['target_price']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On appelle un algorithme de Gradient Boosting regression avec un nombre d'arbre de 1000. Chaque arbre a pour profondeur 4. La fonction de perte est la fonction least squares 'ls'. Le parammetre learning_rate=0.01. On prend random_sate=2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "             presort='auto', random_state=2018, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor(n_estimators=1000,max_depth=4,\\\n",
    "                                learning_rate=0.01,random_state=2018)\n",
    "GBR.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) On affiche l'écart quadratique moyen, l'écart absolue moyen et le score r2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :7.05418284309\n",
      "MAE :2.02317032215\n",
      "R2 :0.930363329128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "print('MSE :'+str(mean_squared_error(Y_test,GBR.predict(X_test))))\n",
    "print('MAE :'+str(mean_absolute_error(Y_test,GBR.predict(X_test))))\n",
    "print('R2 :'+str(r2_score(Y_test,GBR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :0.928073189501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor(n_estimators=1000,max_depth=4,\\\n",
    "                                learning_rate=0.01,random_state=2018)\n",
    "GBR.fit(X_train,Y_train)\n",
    "print('R2 :'+str(r2_score(Y_test,GBR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) On va tracer sur un même graphique:\n",
    "* le score r2 de l'ensemble d'apprentissage en fonction de max_depth, la profondeur de l'arbre\n",
    "* le score r2 de l'ensemble de test en fonction de max_depth, la profondeur de l'arbre\n",
    "\n",
    "Les autres paramêtres sont constants: n_estimators=1000, learning_rate=0.01,random_state=2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5fc32ff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "res = []\n",
    "for i in range(1,11):\n",
    "    clf = GradientBoostingRegressor(loss='ls',learning_rate=0.01,\\\n",
    "                                    n_estimators=1000,max_depth=i,\\\n",
    "                                    max_features=X_train.shape[1],random_state=2018)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    resultat = [i,r2_score(Y_train,clf.predict(X_train)),r2_score(Y_test,clf.predict(X_test))]\n",
    "    res.append(resultat)\n",
    "    \n",
    "r2_train = [o[1] for o in res]\n",
    "r2_test = [o[2] for o in res]\n",
    "axix = [o[0] for o in res]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(axix,r2_train,label=\"R2 score train_data\")\n",
    "plt.plot(axix,r2_test,label=\"R2 score test_data\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour max_depth entre 1 et 3, on est dans le cas de l'underfitting.<br>\n",
    "On atteint le plus haut score R2 pour l'ensemble de test pour max_depth=4. <br>\n",
    "Pour max_depth supérieur à 4, le score R2 diminue pour l'ensemble de test, masi augmente pour l'ensemble d'entrainement.<br>\n",
    "Pour max_depht=10, on est typiquement dans un cas d'overfitting. Le score R2 de l'ensemble d'entrainement est 1 alors que celui de l'ensemble de test se situe entre 0.88 et 0.90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice à rendre\n",
    "Dans les exercices suivants, on va appliquer des modêles/algorithme de machine learning sur les données assurances.<br>\n",
    "Le lien vers les données : https://www.dropbox.com/s/vatqpotujw0ibnd/insurance.csv?dl=0.<br><br>\n",
    "Les colonnes de ce fichiers sont: age,\tsex, bmi, children,\tsmoker,\tregion,\tcharges.<br>\n",
    "Le butes des exercice est de prédire la variable charge en fonction des autres. Charges est donc la variable cible. Age,\tsex, bmi, children,\tsmoker,\tregion constituent l'ensembles des features.<br> \n",
    "L'exercice 1 à pour but de créer un dataframe pandas à partire du fichier csv assurance. Dans les autres exercices, on utilisera le fichier  assurance.pkl:<br>\n",
    "https://www.dropbox.com/s/54dqzm5wsa7b0z2/insurance.pkl?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 (création du Dataframe assurance)\n",
    "* Importer le fichier assurance.csv.\n",
    "* Dumifier les variables qui doivent l'être\n",
    "* afficher les premiere lignes du dataframe crée\n",
    "* Exporter le dataframe pandas dans un pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 (Gradient Boosting Regressor sur assurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Diviser le dataframe assurance en échantillon d'apprentissage et de test. La taille de l'échantillon de test représente 33% de la taille du dataframe assurance. On prendra pour paramêtre random_state=1998<br>\n",
    "X_train,Y_train représentent l'échantillon d'apprentissage. X_test,Y_test représentent l'échantillon de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#votre code ici\n",
    "import pandas as pd\n",
    "rep = \"/home/fabien/Bureau/Python Dauphine/DATABASE/insurance.pkl\"\n",
    "assurance = pd.read_pickle(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) \n",
    "* Appeller un modele du Gradient Boosting Regressor avec les parametres suivants: n_estimators=390, max_depth=4, learning_rate=0.01, random_state=2018)\n",
    "* Entrainer le modêle sur X_train, et Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Afficher le score R2, l'écart absolue moyen du modele crée précedement. Ces scores portent sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) On va tracer sur un même graphique:\n",
    "* le score r2 de l'ensemble d'apprentissage en fonction de max_depth, la profondeur de l'arbre\n",
    "* le score r2 de l'ensemble de test en fonction de max_depth, la profondeur de l'arbre\n",
    "\n",
    "Les autres paramêtres sont constants: n_estimators=400, learning_rate=0.01,random_state=2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#votre code ici\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercice 2 (Neural network Regressor sur assurance)\n",
    "1) Diviser le dataframe assurnace en échantillon d'apprentissage et de test les donnée assurance. La taille de l'échantillon de test représente 20% de la taille du dataframe assurance. On prendra pour paramêtre random_state=2003<br>\n",
    "X_train,Y_train représentent l'échantillon d'apprentissage. X_test,Y_test représentent l'échantillon de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rep = \"/home/fabien/Bureau/Python Dauphine/DATABASE/insurance.pkl\"\n",
    "assurance = pd.read_pickle(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Créer un modele de réseau de neurone de regression avec 2 couches caché ayant respectivement 10 perceptrons dans la première couche et 10 perceptrons dans la deuxième couche.\n",
    "* L'algorithme minimisant la perte sera de type newtonien. \n",
    "* Le nombre d'itération maximum est 1000\n",
    "* La fonction d'activation sera relu\n",
    "* La contraint L2 alpha sera la valeur par défault\n",
    "* random_state=2000\n",
    "\n",
    "Ce modele s'appelle NN1. Lancer l'apprentissage du modele (NN1.fit) sur l'ensemble d'aprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calculer l'erreur moyenne absolue et le score r2 du modele NN1 sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) a ) Déterminer les poids du réseau de neurone NN1 allant du neurone 3 de la couche caché 1 à l'ensemble des neurones de la couche caché 2. (En python on commence en 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Déterminer le poids allant du neurone 3 de la couche cachée 1 au neurone 5 de la couche cachée 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Déterminer les biais de la couche caché 2. On utilisera la fonction intercepts_. On a des biais uniquement dans les couches cachées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Déterminer le biais du perceptron 3 de la couche caché 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) On pose:<br>\n",
    "$\\begin{eqnarray*}\n",
    "N_{i} &=& \\mbox{number of input neurons}\\\\\n",
    "N_{o} &=& \\mbox{number of output neurons}\\\\\n",
    "N_{s} &=& \\mbox{number of samples in training data}\\\\\n",
    "\\alpha &=& \\mbox{an arbitrary scaling factor usually 2-10.}\\\\\n",
    "N_{h} &=& \\frac{N_{s}}{(\\alpha (N_{i}+N_{o}))} \\mbox{upper bound on the number of hidden neurons that won't result in over-fitting}.\n",
    "\\end{eqnarray*}$<br><br>\n",
    "<b>Calculer $N_{h}$ pour $\\alpha = 5$. Afficher $N_{h}$ <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Utiliser gridsearch cv pour faire une validation croisé de type 5 fold cross validation dans le bute d'optimiser le score r2.<br>\n",
    "Cette validation croisé sera faites sur des réseaux de neurones à 2 couches cachées.<br>\n",
    "Le nombre de perceptron de chaque couche va de 11 à 19.<br>\n",
    "On prendra random_state=2000, activation='relu' et solver='lbfgs', max_iter = 800.<br>\n",
    "Afficher ensuite dans une autre cellule le meilleur score de votre gridsearchcv.<br>\n",
    "Affiche dans une autre cellule les meilleurs paramêtres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Faire un algorithme de réseaux de neurone NN_best avec les meilleurs parametres determinés à la question 6. Lancer l'apprentissage sur X_train et Y_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Calculer les score r2 de NN_best sur les données de test et afficher ce dernier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 (Epsilon-Support Vector Regression sur le dataframe assurance)\n",
    "1) Diviser le dataframe assurance en échantillon d'apprentissage et de test les donnée assurance. La taille de l'échantillon de test représente 20% de la taille du dataframe assurance. On prendra pour paramêtre random_state=2003<br>\n",
    "X_train,Y_train représentent l'échantillon d'apprentissage. X_test,Y_test représentent l'échantillon de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Scaler les donner X_train et X_test. Les résultats serons stocker dans X_train_scal et Y_train_scal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Utiliser un Epsilon-Support Vector Regression avec comme parametre kernel='linear',C=200, epsilon=1, gamma=0.08. On appelera ce modele SVMR. Entrainez SVRM sur X_train et Y_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Calculer le score r2 des données de test scalées et afficher ce dernier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Utiliser un Epsilon-Support Vector Regression avec comme paramêtre kernel='poly',C=800, epsilon=1, degree=3. On appelera ce modêle SVMRPOLY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) On va tracer sur un même graphique:\n",
    "* le score r2 d'un SVR sur l'ensemble d'apprentissage en fonction du degree du polynome \n",
    "* le score r2 du même SVR l'ensemble de test en fonction du degree du polynome \n",
    "\n",
    "Les autres paramêtres sont constants: kernel='poly', C=800, epsilon=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 (RandomForestRegressor)\n",
    "Utilisez la fonctionalité gridsearchcv sur des RandomForestRegressor pour prédire au mieux la variable charge.<br>\n",
    "Vous devrez donc trouver le meilleur algorithme possible de random forest au sens du score r2.<br>\n",
    "Indication sur la grille des parametre:<br>\n",
    "parameters = {'n_estimators':list(range(20,80)),'max_depth':list(range(3,15)),\n",
    "              'max_features':list(range(5,12))}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
